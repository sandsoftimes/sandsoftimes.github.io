I"ß<p>Here iâ€™ve discussed the complete Architecture of Gated Recurrent Unit. This is a type of RNN pretty similar to LSTM but a bit faster from the LSTM. Although it outperforms the LSTM in some problems while there are some cases where you still need to use LSTMâ€™s. It is better to test out both techniques to find good results on your problem.</p>

<p>Here is some basic intuition and introduction GRU,</p>

<p><img src="/assets/images/clt/gated-recurrent-unit/1.png" alt="1" /></p>

<p>similary here is some sentences with timestamps along with the Update and Rest gates.</p>

<p><img src="/assets/images/clt/gated-recurrent-unit/2.png" alt="2" /></p>

<p>rest gate working is down below,</p>

<p><img src="/assets/images/clt/gated-recurrent-unit/3.png" alt="3" /></p>

<p>here is some mathematical chart representation,</p>

<p><img src="/assets/images/clt/gated-recurrent-unit/4.png" alt="4" /></p>

<p>a basic neural netwok representation with point-wise addition b/w rest game and previous hidden state/context</p>

<p><img src="/assets/images/clt/gated-recurrent-unit/5.png" alt="5" /></p>

<p>update gate working and final hidden state/context calculation,</p>

<p><img src="/assets/images/clt/gated-recurrent-unit/6.png" alt="6" /></p>
:ET